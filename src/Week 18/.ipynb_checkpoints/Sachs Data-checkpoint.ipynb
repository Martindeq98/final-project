{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7560cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bnlearn as bb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# our methods\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import helper.helper as h\n",
    "import helper.methods as m\n",
    "\n",
    "# notears\n",
    "from notears.notears.notears import linear\n",
    "from notears.notears.notears import utils\n",
    "\n",
    "from importlib import reload  # Python 3.4+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e95f59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(h);\n",
    "reload(m);\n",
    "reload(linear);\n",
    "reload(utils);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3412dc",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13135ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load unmodified SACHS data\n",
    "X = np.loadtxt(\"../../data/real_data/sem/gene_sachs/data.raw.txt\", skiprows = 1);\n",
    "\n",
    "# zero-mean version\n",
    "X_a = X - np.mean(X, axis = 0)\n",
    "\n",
    "# true adjacency matrix, note: discussiona bout the truth!\n",
    "adj = np.round(bnlearn.bnlearn.import_DAG('sachs', checkmodel = False, verbose = 0)['adjmat'].to_numpy());\n",
    "\n",
    "print(f\"Loaded Sachs unmodified data, consisting of {np.shape(X)[1]} variables, and {np.shape(X)[0]} measurements.\")\n",
    "\n",
    "plt.figure(figsize = (12, 3))\n",
    "plt.plot(X);\n",
    "plt.show()\n",
    "plt.figure(figsize = (12, 3))\n",
    "plt.plot(X_a);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f8b470",
   "metadata": {},
   "source": [
    "### Perform NOTEARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b640ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform notears with the usual lambda, no threshold (very small to remove the \"near-precision\" values)\n",
    "W_NOTEARS, h_val = m._notears_2(X, lambda1 = 0.0, w_threshold = 1e-3, loss_type = \"l2\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4841be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual thresholding\n",
    "threshold = 0.3\n",
    "W_NOTEARS_THRESHOLD = W_NOTEARS.copy()\n",
    "W_NOTEARS_THRESHOLD[np.abs(W_NOTEARS_THRESHOLD) < threshold] = 0\n",
    "print(f\"W_NOTEARS, thresholded with value {threshold}, and {len(W_NOTEARS[np.abs(W_NOTEARS) > threshold])} edges:\\n{np.round(W_NOTEARS_THRESHOLD, 1)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cf72d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare, use thresholding matrix\n",
    "print(utils.count_accuracy(adj, W_NOTEARS_THRESHOLD != 0))\n",
    "print(utils.count_accuracy(adj, W_NOTEARS != 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21a8e5d",
   "metadata": {},
   "source": [
    "### OMP\n",
    "#### Stupid approach (hopefully does not work, OMP for VAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366c7b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OMP as if sachs data was VAR, which it obviously is not\n",
    "W_OMP_var, Ws_var, mses_var, _ = m._OMP_2(X[:-1], X[1:], max_coefs = 60, output = True)\n",
    "\n",
    "# mean squared error is much better, but that is because it is zero-meaned\n",
    "plt.plot(mses_var, label = \"OMP_VAR\")\n",
    "\n",
    "# OMP as if sachs data was VAR, which it obviously is not\n",
    "W_OMP_var_a, Ws_var_a, mses_var_a, _ = m._OMP_2(X_a[:-1], X_a[1:], max_coefs = 60, output = True)\n",
    "\n",
    "# mean squared error is much better, but that is because it is zero-meaned\n",
    "plt.plot(mses_var_a, label = \"OMP_VAR_0MEAN\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90d0ac8",
   "metadata": {},
   "source": [
    "#### SEM approach, hopefully works better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3019d35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_OMP_sem, Ws_sem, mses_sem, _ = m._OMP_SEM(X, max_coefs = 30, output = True)\n",
    "plt.plot(mses_sem, label = \"OMP_SEM\")\n",
    "\n",
    "W_OMP_sem_a, Ws_sem_a, mses_sem_a, _ = m._OMP_SEM(X_a, max_coefs = 30, output = True)\n",
    "plt.plot(mses_sem_a, label = \"OMP_SEM_0MEAN\")\n",
    "\n",
    "plt.scatter(len(B_NOTEARS[np.abs(W_NOTEARS_THRESHOLD) > 0]), h.MSE(W_NOTEARS_THRESHOLD, X, is_sem = True), marker = 'x', label = \"NOTEARS\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbd8b42",
   "metadata": {},
   "source": [
    "### Compare Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bddf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "notears_score = h.score(X, W_NOTEARS_THRESHOLD, adj, printing = False, is_sem = True)\n",
    "notears_score_a = h.score(X_a, W_NOTEARS_THRESHOLD, adj, printing = False, is_sem = True)\n",
    "print(notears_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603ea8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_OMP_SEM = []\n",
    "accs_OMP_SEM_a = []\n",
    "mses_OMP_SEM = []\n",
    "mses_OMP_SEM_a = []\n",
    "mses_OMP_SEM_on_Xa = []\n",
    "mses_OMP_SEM_a_on_Xa = []\n",
    "\n",
    "for W in Ws_sem:\n",
    "    accs_OMP_SEM.append(h.score(X, W, adj, printing = False, is_sem = True)[3])\n",
    "    mses_OMP_SEM.append(h.score(X, W, adj, printing = False, is_sem = True)[5])\n",
    "    mses_OMP_SEM_on_Xa.append(h.score(X_a, W, adj, printing = False, is_sem = True)[5])\n",
    "    \n",
    "for W in Ws_sem_a:\n",
    "    accs_OMP_SEM_a.append(h.score(X, W, adj, printing = False, is_sem = True)[3])\n",
    "    mses_OMP_SEM_a.append(h.score(X, W, adj, printing = False, is_sem = True)[5])\n",
    "    mses_OMP_SEM_a_on_Xa.append(h.score(X_a, W, adj, printing = False, is_sem = True)[5])\n",
    "\n",
    "plt.title(\"Mean Squared Errors of OMP_SEM and NOTEARS compared to raw X\")\n",
    "plt.plot(mses_OMP_SEM, label = \"OMP_SEM\")\n",
    "plt.plot(mses_OMP_SEM_a, label = \"OMP_SEM_0MEAN_BACK\")\n",
    "plt.scatter(len(B_NOTEARS[np.abs(B_NOTEARS) > 0]), notears_score[5], marker = 'x', label = \"NOTEARS\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Mean Squared Errors of OMP_SEM and NOTEARS compared to zero-mean X\")\n",
    "plt.plot(mses_OMP_SEM_on_Xa, label = \"OMP_SEM\")\n",
    "plt.plot(mses_OMP_SEM_a_on_Xa, label = \"OMP_SEM_0MEAN\")\n",
    "plt.scatter(len(B_NOTEARS[np.abs(B_NOTEARS) > 0]), notears_score_a[5], marker = 'x', label = \"NOTEARS\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Accuracies of OMP_SEM and NOTEARS compared to ground truth.\")\n",
    "plt.plot(accs_OMP_SEM, label = \"OMP_SEM\")\n",
    "plt.plot(accs_OMP_SEM_a, label = \"OMP_SEM_0MEAN\")\n",
    "plt.scatter(len(B_NOTEARS[np.abs(B_NOTEARS) > 0]), notears_score[3], marker = 'x', label = \"NOTEARS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3171dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "shd = [[], []]\n",
    "for W in Ws_sem:\n",
    "    shd[0].append(utils.count_accuracy(adj, W != 0)['shd'])\n",
    "    \n",
    "for W in Ws_sem_a:\n",
    "    shd[1].append(utils.count_accuracy(adj, W != 0)['shd'])\n",
    "\n",
    "plt.title(\"Structural Hamming Distances of OMP_SEM and NOTEARS compared to ground truth.\")\n",
    "plt.plot(shd[0], label = 'OMP_SEM')\n",
    "plt.plot(shd[1], label = 'OMP_SEM_0MEAN')\n",
    "plt.scatter(len(B_NOTEARS[np.abs(B_NOTEARS) > 0]), utils.count_accuracy(adj, B_NOTEARS)['shd'], marker = 'x', label = \"NOTEARS\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc329a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Difference between 'optimal' OMP and NOTEARS:\\n{np.round(np.abs(W_NOTEARS_THRESHOLD - Ws_sem_a[19]), 1)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a063c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([np.linalg.norm(W - W_NOTEARS_THRESHOLD, 1) for W in Ws_sem_a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26413993",
   "metadata": {},
   "outputs": [],
   "source": [
    "shds = []\n",
    "for i in range(1, 1000, 1):\n",
    "    threshold = i / 200\n",
    "    \n",
    "    W_t = W_NOTEARS.copy()\n",
    "    W_t[np.abs(W_t) < threshold] = 0\n",
    "    \n",
    "    shds.append(utils.count_accuracy(adj, W_t != 0)['shd'])\n",
    "\n",
    "plt.plot(np.array(range(1, 1000, 1)) / 200, shds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bit874e3a48d9b148faaa09714964fd179b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
