{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3543d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always: Numpy and Plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# LassoLars\n",
    "from sklearn.linear_model import LassoLars\n",
    "\n",
    "# Our helper functions\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import helper.helper as h\n",
    "import helper.methods as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11445e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data name\n",
    "T, n = 100, 2\n",
    "\n",
    "W = np.array([[0.95, -0.25], [1.0, 0.0]])\n",
    "X = h.generate_var_2(T, n, W, np.identity(n))\n",
    "\n",
    "# Load data\n",
    "# data_name = \"X_s4_n3_T100_random_matrix_2\"\n",
    "# W, X, expl = h.load_data(data_name)\n",
    "# print(expl)\n",
    "\n",
    "# Plot data\n",
    "plt.plot(X)\n",
    "\n",
    "# Show true matrix W\n",
    "print(np.round(W, 2))\n",
    "\n",
    "# Useful variables\n",
    "T, n = np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c492cf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_lars_W(X, alpha):\n",
    "    \"\"\"Performs LASSO with Lars on X with regularization value alpha\"\"\"\n",
    "    \n",
    "    # get regressor and variables\n",
    "    y = X[1:]\n",
    "    x = X[:-1]\n",
    "\n",
    "    # initialize W_hat\n",
    "    W_hat = np.array([])\n",
    "\n",
    "    # Get our regularization method\n",
    "    reg = LassoLars(alpha=alpha, normalize=False)\n",
    "    \n",
    "    # get parameters\n",
    "    for i in range(n):\n",
    "        est = reg.fit(x, y[:, i])\n",
    "        W_hat = np.append(W_hat, est.coef_)\n",
    "\n",
    "    # return W_hat after reshape\n",
    "    return W_hat.reshape((n, n)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e5de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lingnam_lasso_lars(X, step_size = 0.1):\n",
    "    \"\"\"Incrementally increase penalty by step_size until we have aa DAG\"\"\"\n",
    "    \n",
    "    # initial L1 penalty\n",
    "    l, r = 0, 1\n",
    "    \n",
    "    # get W_hat with 0 penalty -> OLS\n",
    "    W_ols = lasso_lars_W(X, alpha)\n",
    "    W_hat = W_ols.copy()\n",
    "    \n",
    "    # while we do not have a dag\n",
    "    while not h.is_dag(W_hat):\n",
    "        # increase alpha and do lasso with increased alpha\n",
    "        alpha += step_size\n",
    "        W_hat = lasso_lars_W(X, alpha)\n",
    "\n",
    "    # return W_hat and print smallest alpha\n",
    "    print(f\"Smallest alpha for DAG: {round(alpha, 5)}.\")\n",
    "    return W_hat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bit874e3a48d9b148faaa09714964fd179b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
