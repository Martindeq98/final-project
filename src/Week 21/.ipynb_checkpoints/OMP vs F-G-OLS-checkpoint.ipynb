{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17aeeeb7",
   "metadata": {},
   "source": [
    "### OMP vs F-G-OLS\n",
    "We have discussed that there are two methods, Orthogonal Matching Pursuit and Forward-Greedy-Ordinary Least Squares. \n",
    "\n",
    "Let us first assume the one-dimensional example. Assume that we have data $\\mathbf{X} \\in \\mathbb{R}^{T \\times p}$, and we have a signal defined as $$Y = X w,$$ where $Y \\in \\mathbb{R}^T$, and $w \\in \\mathbb{R}^p$.\n",
    "\n",
    "Assume we already have a set of $k$ atoms, $\\Gamma^k$. Then, the current residual is $$r_k = X_{\\Gamma^k} w_{\\Gamma^k} - Y.$$ Both methods iteratively add the next \"best\" possible atom. They only differ in their definition of \"best\". \n",
    "- For OMP, we pick the atom that is most correlated with the residual. In mathematical notation:\n",
    "\n",
    "$$i_{k+1} = \\underset{i}{\\arg \\max} |\\tilde{x_i} X_{\\Gamma^k \\cup i} r_k|$$\n",
    "\n",
    "- For F-G-OLS, we pick the atom that minimizes the residual error. In mathematical notation:\n",
    "\n",
    "$$i = \\underset{i}{\\arg \\min} ||Y - X_{\\Gamma^k \\cup i} X_{\\Gamma^k \\cup i}^\\dagger Y||_2$$\n",
    "\n",
    "Both methods have the exact same goal, find a subset $\\Gamma^k$ and an accompanying coefficient vector $\\tilde{w}$ such that $X_{\\Gamma^k}w$ approximates $Y$ well, thereby minimizing the residual error. However, their criteria slightly differ.\n",
    "\n",
    "The question is: when do the methods yield a different choice?\n",
    "\n",
    "From [this paper](https://eprints.soton.ac.uk/142469/1/BDOMPvsOLS07.pdf) we see that they are not the same, and give a geographical interpretation. For this, we consider a three-dimensional example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "9b206f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import helper.helper as h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c12e80b",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "ba1081ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of samples, number of variables\n",
    "T, p = 20, 10\n",
    "\n",
    "## Generate random X\n",
    "X = np.random.rand(T, p)\n",
    "\n",
    "# for i in range(p):\n",
    "#     X[:, i] = normalize(X[:, i])\n",
    "\n",
    "## Generate true coefficient vector w\n",
    "w = range(p) + np.ones(p)\n",
    "\n",
    "## Compute Y\n",
    "Y = X @ w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9811a5",
   "metadata": {},
   "source": [
    "### OMP Implementation of $\\texttt{sklearn}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "133449af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.   0.   4.99]\n"
     ]
    }
   ],
   "source": [
    "omp = OrthogonalMatchingPursuit(n_nonzero_coefs = 1, normalize = True, fit_intercept = False)\n",
    "omp_fit = omp.fit(X, Y)\n",
    "print(np.round(omp_fit.coef_, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ead9259",
   "metadata": {},
   "source": [
    "### One step of Orthogonal Matching Pursuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "592cba26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.064 4.538 2.605]\n",
      "[8.163 8.467 9.246]\n"
     ]
    }
   ],
   "source": [
    "OLS_gains = OLS_GAINS(X, Y, [])[3]\n",
    "OMP_gains = OMP_GAINS(X, Y, np.zeros(p))\n",
    "\n",
    "print(np.round(OLS_gains, 3))\n",
    "print(np.round(OMP_gains, 3))\n",
    "\n",
    "for i in range(p):\n",
    "    if np.argmax(OLS_gains) != np.argmin(OMP_gains):\n",
    "        print(\"Order is not equivalent\")\n",
    "        \n",
    "    OLS_gains = np.delete(OLS_gains, np.argmax(OLS_gains))\n",
    "    OMP_gains = np.delete(OMP_gains, np.argmin(OMP_gains))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "3994bd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OMP_GAINS(X, Y, w):\n",
    "    r = Y - X @ w\n",
    "    return [np.abs(np.dot(normalize(x), r)) for x in X.T]\n",
    "\n",
    "def OLS(X, Y, F):\n",
    "    F_copy = F.copy()\n",
    "    F_copy.sort()\n",
    "    w = np.zeros(p)\n",
    "    w[F_copy] = np.linalg.pinv(X[:, F_copy]) @ Y\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "031ca71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OMP:\n",
      "Residual Correlations: [8.16 8.47 9.25].\n",
      "Index Maximizing Residual Correlation: 2.\n",
      "Resulting vector w: [0.   0.   4.99].\n"
     ]
    }
   ],
   "source": [
    "### Initialize variables\n",
    "w, F = np.zeros(p), []\n",
    "\n",
    "### Get residual correlations\n",
    "print(f\"OMP:\\nResidual Correlations: {np.round(OMP_GAINS(X, Y, w), 2)}.\")\n",
    "\n",
    "### Find largest one\n",
    "F.append(np.argmax(OMP_GAINS(X, Y, w)))\n",
    "print(f\"Index Maximizing Residual Correlation: {np.argmax(OMP_GAINS(X, Y, w))}.\")\n",
    "\n",
    "### Create new vector w\n",
    "print(f\"Resulting vector w: {np.round(OLS(X, Y, F), 2)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9244fc",
   "metadata": {},
   "source": [
    "### One step of Orthogonal Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "8d71332c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Index to add: 9 with score 44.3.\n",
      "Results in vector: [ 0.   0.   0.   0.   0.   0.   0.   0.   0.  38.1].\n"
     ]
    }
   ],
   "source": [
    "def OLS_GAINS(X, Y, F):\n",
    "    \n",
    "    gains = []\n",
    "    \n",
    "    best_score, best_index, best_w = np.inf, None, np.zeros(p)\n",
    "    \n",
    "    for i in range(p):\n",
    "        if i not in F:\n",
    "\n",
    "            w = np.zeros(p)\n",
    "            \n",
    "            # append i to index\n",
    "            F.append(i)\n",
    "\n",
    "            # compute vector w\n",
    "            w[F] = np.linalg.pinv(X[:, F]) @  Y\n",
    "\n",
    "            # print residual\n",
    "            # print(f\"Residual for adding index {i}: {round(np.linalg.norm(Y - X @ w), 2)}.\")\n",
    "            \n",
    "            gains.append(np.linalg.norm(Y - X @ w))\n",
    "            \n",
    "            # compute residual\n",
    "            if np.linalg.norm(Y - X @ w) < best_score:\n",
    "                best_w = w.copy()\n",
    "                best_score = np.linalg.norm(Y - X @ w)\n",
    "                best_index = i\n",
    "\n",
    "            F.remove(i)\n",
    "\n",
    "    return best_index, best_w, best_score, gains\n",
    "\n",
    "best_index, best_w, best_score, OLS_gains = OLS_GAINS(X, Y, [])\n",
    "\n",
    "print(f\"\\nBest Index to add: {best_index} with score {round(best_score, 2)}.\\nResults in vector: {np.round(best_w, 2)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80de1ea9",
   "metadata": {},
   "source": [
    "### Full F-GLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "a1cf4a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Index to add: 9 with score 44.3.\n",
      "Results in vector: [ 0.   0.   0.   0.   0.   0.   0.   0.   0.  38.1].\n",
      "\n",
      "Best Index to add: 5 with score 20.16.\n",
      "Results in vector: [ 0.    0.    0.    0.    0.   31.34  0.    0.    0.   24.33].\n",
      "\n",
      "Best Index to add: 8 with score 16.74.\n",
      "Results in vector: [ 0.    0.    0.    0.    0.   25.83  0.    0.    9.53 20.57].\n"
     ]
    }
   ],
   "source": [
    "F = []\n",
    "best_index, best_w, best_score, gains = OLS_GAINS(X, Y, F)\n",
    "F.append(best_index)\n",
    "print(f\"\\nBest Index to add: {best_index} with score {round(best_score, 2)}.\\nResults in vector: {np.round(best_w, 2)}.\")\n",
    "\n",
    "best_index, best_w, best_score, gains = OLS_GAINS(X, Y, F)\n",
    "F.append(best_index)\n",
    "print(f\"\\nBest Index to add: {best_index} with score {round(best_score, 2)}.\\nResults in vector: {np.round(best_w, 2)}.\")\n",
    "\n",
    "best_index, best_w, best_score, gains = OLS_GAINS(X, Y, F)\n",
    "F.append(best_index)\n",
    "print(f\"\\nBest Index to add: {best_index} with score {round(best_score, 2)}.\\nResults in vector: {np.round(best_w, 2)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633e5205",
   "metadata": {},
   "source": [
    "### Full F-OMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "8a396f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OMP:\n",
      "Residual Correlations: [102.93 103.91 103.33 107.2  107.09 107.03 107.22  97.57 107.68 111.24].\n",
      "Index Maximizing Residual Correlation: 9.\n",
      "Resulting vector w: [ 0.   0.   0.   0.   0.   0.   0.   0.   0.  38.1].\n",
      "\n",
      "Step 2:\n",
      "Residual Correlations: [15.22 12.61 12.65 16.21 12.02 27.63 20.81 22.64 17.88  0.  ].\n",
      "Index Maximizing Residual Correlation: 5.\n",
      "Resulting vector w: [ 0.    0.    0.    0.    0.   31.34  0.    0.    0.   24.33].\n",
      "\n",
      "Step 3:\n",
      "Residual Correlations: [4.22 1.84 5.78 3.12 1.18 0.   5.38 4.32 5.64 0.  ].\n",
      "Index Maximizing Residual Correlation: 2.\n",
      "Resulting vector w: [ 0.    0.    6.14  0.    0.   28.72  0.    0.    0.   20.19].\n"
     ]
    }
   ],
   "source": [
    "### Initialize variables\n",
    "w, F = np.zeros(p), []\n",
    "\n",
    "### Get residual correlations\n",
    "print(f\"OMP:\\nResidual Correlations: {np.round(OMP_GAINS(X, Y, w), 2)}.\")\n",
    "\n",
    "### Find largest one\n",
    "F.append(np.argmax(OMP_GAINS(X, Y, w)))\n",
    "print(f\"Index Maximizing Residual Correlation: {np.argmax(OMP_GAINS(X, Y, w))}.\")\n",
    "\n",
    "### Create new vector w\n",
    "print(f\"Resulting vector w: {np.round(OLS(X, Y, F), 2)}.\")\n",
    "\n",
    "### Get residual correlations\n",
    "print(f\"\\nStep 2:\\nResidual Correlations: {np.round(OMP_GAINS(X, Y, OLS(X, Y, F)), 2)}.\")\n",
    "\n",
    "### Find largest one\n",
    "print(f\"Index Maximizing Residual Correlation: {np.argmax(OMP_GAINS(X, Y, OLS(X, Y, F)))}.\")\n",
    "F.append(np.argmax(OMP_GAINS(X, Y, OLS(X, Y, F))))\n",
    "\n",
    "### Create new vector w\n",
    "print(f\"Resulting vector w: {np.round(OLS(X, Y, F), 2)}.\")\n",
    "\n",
    "### Get residual correlations\n",
    "print(f\"\\nStep 3:\\nResidual Correlations: {np.round(OMP_GAINS(X, Y, OLS(X, Y, F)), 2)}.\")\n",
    "\n",
    "### Find largest one\n",
    "print(f\"Index Maximizing Residual Correlation: {np.argmax(OMP_GAINS(X, Y, OLS(X, Y, F)))}.\")\n",
    "F.append(np.argmax(OMP_GAINS(X, Y, OLS(X, Y, F))))\n",
    "\n",
    "### Create new vector w\n",
    "print(f\"Resulting vector w: {np.round(OLS(X, Y, F), 2)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "154035e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "T, p = 20, 10\n",
    "\n",
    "X = np.random.rand(T, p)\n",
    "w = range(p) + np.ones(p)\n",
    "Y = X @ w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "960009a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]),\n",
       " [4, 9, 6, 8, 5, 7, 3, 2, 1, 0])"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def OLS_full(X, Y):\n",
    "    \n",
    "    # initialize w\n",
    "    w = np.zeros(p)    \n",
    "    \n",
    "    # initialize importance order\n",
    "    F = []\n",
    "    \n",
    "    # iteratively add edge\n",
    "    for i in range(p):\n",
    "        best_index, best_w, best_score, gains = OLS_GAINS(X, Y, F)\n",
    "        \n",
    "        if best_index != None:\n",
    "            F.append(best_index)\n",
    "    \n",
    "    return best_w, F\n",
    "\n",
    "OLS_full(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135a71e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OMP_full(X, Y):\n",
    "    \n",
    "    # initialize w\n",
    "    w = np.zeros(p)    \n",
    "    \n",
    "    # initialize importance order\n",
    "    F = []\n",
    "    \n",
    "    # iteratively add edge\n",
    "    for i in range(p):\n",
    "        ### Get residual correlations\n",
    "        F.append(np.argmax(OMP_GAINS(X, Y, w)))\n",
    "        w = OLS(X, Y, F)\n",
    "        \n",
    "    return w, F\n",
    "\n",
    "OMP_full(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3484178",
   "metadata": {},
   "source": [
    "### Is there sometimes a difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98af2d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for a in range(100):\n",
    "    \n",
    "    print(a * 100)\n",
    "    \n",
    "    for _ in range(100):\n",
    "        ### Generate data\n",
    "        T, p = 10, 1000\n",
    "\n",
    "        ## Generate random X\n",
    "        X = np.random.rand(T, p)\n",
    "\n",
    "        ## Generate true coefficient vector w\n",
    "        w = np.random.rand(p)\n",
    "\n",
    "        ## Compute Y\n",
    "        Y = X @ w\n",
    "\n",
    "        ### Compute next index of OMP\n",
    "        OMP_index = np.argmax(OMP_GAINS(X, Y, np.zeros(p)))\n",
    "\n",
    "        ### Compute next index of F-GLS\n",
    "        GLS_index = OLS_GAINS(X, Y, [])[0]\n",
    "\n",
    "        ### Verify equivalence\n",
    "        if OMP_index != GLS_index:\n",
    "            print(X, Y, w)\n",
    "        \n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9043ff90",
   "metadata": {},
   "source": [
    "### Conjecture, OMP seems to be equal to OLS for normalized stuff, strange.\n",
    "If we generate any random data $X$, and any random coefficient vector $w$, OMP and OLS always seem to pick the exact same vectors, which is strange as the paper suggests that this is not necessarily the case. Also, OLS is order $k$ slower so OLS seems to be the \"smarter\" choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245f4adf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bit874e3a48d9b148faaa09714964fd179b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
