{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "65f00954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "770db827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9 0.  0. ]\n",
      " [0.9 0.  0. ]\n",
      " [0.  0.9 0. ]] [[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# n = 3\n",
    "np.random.seed(seed = 1)\n",
    "\n",
    "length, n = 500, 3\n",
    "A, P, Sigma = None, None, None \n",
    "\n",
    "if n == 2:\n",
    "    A = np.array([[0.4, 0.9], [0.1, 0.4]])\n",
    "    P = np.array([[1.0, 0.0], [0.0, 1.0]])\n",
    "    Sigma = np.identity(n)\n",
    "elif n == 3:\n",
    "    A = np.array([[0.9, 0.0, 0.0], [0.9, 0.0, 0.0], [0.0, 0.9, 0.0]])\n",
    "    Sigma = np.array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]])\n",
    "    P = np.array([[0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0]])\n",
    "elif n == 4:\n",
    "    A = np.array([[0.9, 0.0, 0.0, 0.0], [0.9, 0.0, 0.0, 0.0], [0.0, 0.9, 0.0, 0.0], [0.0, 0.0, 0.9, 0.0]])\n",
    "    Sigma = np.identity(n)\n",
    "    P = np.array([[0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0]])\n",
    "else:\n",
    "    A = np.zeros((n, n))\n",
    "    A[0][0] = 0.9\n",
    "    for i in range(1, n):\n",
    "        A[i][i - 1] = 0.9\n",
    "    P = np.identity(n)\n",
    "    Sigma = np.identity(n)\n",
    "    \n",
    "As, Ps = A.copy(), P.copy()\n",
    "\n",
    "a_parms = int(n * (n + 1) / 2)\n",
    "p_parms = np.math.factorial(n)\n",
    "\n",
    "print(A, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "d93108a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2679491924311228\n"
     ]
    }
   ],
   "source": [
    "def expected_cost(A, P, As = As, Ps = Ps):\n",
    "    # base on the distribution of X, no actual data needed.\n",
    "    # we need the covariance of X_t - X_{t-1}.\n",
    "    # Then, the expected cost is the trace of this covariance\n",
    "    P_inv = np.linalg.inv(P)\n",
    "    Ps_inv = np.linalg.inv(Ps)\n",
    "    \n",
    "    B = np.matmul(P_inv, np.matmul(A, P))\n",
    "    Bs = np.matmul(Ps_inv, np.matmul(As, Ps))\n",
    "    \n",
    "    covariance_X = np.matmul(np.linalg.inv(np.identity(n ** 2) - np.kron(Bs, Bs)), Sigma.reshape(n ** 2)).reshape((n, n))\n",
    "    \n",
    "    covariance_matrix = Sigma + np.matmul((Bs - B), np.matmul(covariance_X, (Bs - B).transpose()))\n",
    "    \n",
    "    return np.trace(covariance_matrix) - 1 * np.linalg.norm(P, 'f')\n",
    "\n",
    "print(expected_cost(As, Ps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "ea3e9802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2. 2. 2.]\n",
      " [2. 2. 2.]\n",
      " [2. 2. 2.]]\n"
     ]
    }
   ],
   "source": [
    "p_coefs = np.ones(p_parms)\n",
    "permutation_list = itertools.permutations(np.identity(n))\n",
    "permutation_list = np.array(list(permutation_list))\n",
    "\n",
    "total = sum(p * c for p, c in zip(p_coefs, permutation_list))\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "e8538a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.031458342920567"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "permutation_list = itertools.permutations(np.identity(n))\n",
    "permutation_list = np.array(list(permutation_list))\n",
    "\n",
    "def expected_cost_opt(variables):\n",
    "    # create A\n",
    "    A = np.zeros((n, n))\n",
    "    A[np.tril_indices(n)] = variables[:a_parms]\n",
    "    \n",
    "    # create P\n",
    "    p_coefs = variables[a_parms:]\n",
    "    P = sum(p * c for p, c in zip(p_coefs, permutation_list))\n",
    "    \n",
    "    ## compute expected cost\n",
    "    # compute inverses\n",
    "    P_inv = np.linalg.inv(P)\n",
    "    Ps_inv = np.linalg.inv(Ps)\n",
    "    \n",
    "    # compute B\n",
    "    B = np.matmul(P_inv, np.matmul(A, P))\n",
    "    Bs = np.matmul(Ps_inv, np.matmul(As, Ps))\n",
    "    \n",
    "    # compute covariance of X\n",
    "    covariance_X = np.matmul(np.linalg.inv(np.identity(n ** 2) - np.kron(Bs, Bs)), Sigma.reshape(n ** 2)).reshape((n, n))\n",
    "    \n",
    "    # compute covariance of X_{val} - X_{pred}\n",
    "    covariance_matrix = Sigma + np.matmul((Bs - B), np.matmul(covariance_X, (Bs - B).transpose()))\n",
    "    \n",
    "    # return cost\n",
    "    return np.trace(covariance_matrix) # - 0.1 * np.linalg.norm(P, 'f')\n",
    "\n",
    "# # set A\n",
    "A = np.tril((np.random.rand(n, n)))\n",
    "\n",
    "# # set P\n",
    "p_coefs = np.append(1.0, np.zeros(p_parms - 1))\n",
    "\n",
    "# # define variables\n",
    "variables = np.append(A[np.tril_indices(n)], p_coefs.flatten())\n",
    "\n",
    "# # compute expected cost\n",
    "expected_cost_opt(variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "02a006f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficients must sum to one\n",
    "def eq_cons(variables):\n",
    "    p_coefs = variables[a_parms:]\n",
    "    return sum(p_coefs) - 1\n",
    "\n",
    "# coefficients must not be negative\n",
    "def ineq_cons(variables):\n",
    "    p_coefs = variables[a_parms:]\n",
    "    return p_coefs - np.zeros(p_parms)\n",
    "\n",
    "cons = [{'type': 'ineq', 'fun': ineq_cons}, {'type': 'eq', 'fun': eq_cons}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "71a01666",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "b637650d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15347904 0.12755623 0.33138101 0.05707333 0.3305104 ]\n"
     ]
    }
   ],
   "source": [
    "a = np.random.rand(5)\n",
    "print(a / np.sum(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "5f6edc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01  0.99  0.01]\n",
      " [ 0.22  0.01  0.76]\n",
      " [ 0.77 -0.    0.23]]\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n",
      "0.3684210526315789\n",
      "3.01749985809515\n",
      "\n",
      "0.3684210526315789\n"
     ]
    }
   ],
   "source": [
    "from scipy import optimize\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1):\n",
    "    results = optimize.minimize(expected_cost_opt, np.random.rand(a_parms + p_parms), constraints = cons)\n",
    "    p_coefs = results.x[a_parms:]\n",
    "    p_perm = np.array(sum(p * c for p, c in zip(p_coefs, permutation_list)))\n",
    "    print(np.round(p_perm, 2))\n",
    "    print(closest_perm(p_perm))\n",
    "    scores.append(np.sum(closest_perm(p_perm) == Ps) == n ** 2)\n",
    "    print(sum(scores) / len(scores))\n",
    "    print(results.fun)\n",
    "\n",
    "print()\n",
    "print(sum(scores) / len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3732387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_perm(P_DS):\n",
    "    # convert to get the maximum linear assignment problem\n",
    "    P_MOD = np.ones((n, n)) * np.max(P_DS) - P_DS\n",
    "    \n",
    "    # apply the maximum linear assignment algorithm\n",
    "    row_ind, col_ind = optimize.linear_sum_assignment(P_MOD)\n",
    "\n",
    "    # initialize Permutation matrix to return\n",
    "    P_perm = np.zeros((n, n))\n",
    "\n",
    "    # fill in permutation matrix\n",
    "    for row, col in zip(row_ind, col_ind):\n",
    "        P_perm[row][col] = 1 \n",
    "    \n",
    "    # re\n",
    "    return P_perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "31199030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "[[ 0.88  0.    0.  ]\n",
      " [ 0.7   0.22  0.  ]\n",
      " [ 0.18  0.99 -0.25]]\n",
      "\n",
      "P:\n",
      "[[ 0.01  0.99  0.01]\n",
      " [ 0.22  0.01  0.76]\n",
      " [ 0.77 -0.    0.23]]\n",
      "\n",
      "\n",
      "Grad(A[1][1]: -0.22.\n",
      "Grad(A[2][1]: -0.0.\n",
      "Grad(A[2][2]: -0.0.\n",
      "Grad(A[3][1]: 0.23.\n",
      "Grad(A[3][2]: 0.3.\n",
      "Grad(A[3][3]: 0.22.\n",
      "\n",
      "Grad(P[1][1]: 0.37.\n",
      "Grad(P[1][2]: 0.04.\n",
      "Grad(P[1][3]: 0.03.\n",
      "Grad(P[2][1]: 0.39.\n",
      "Grad(P[2][2]: 0.22.\n",
      "Grad(P[2][3]: 0.27.\n",
      "Grad(P[3][1]: -0.36.\n",
      "Grad(P[3][2]: -0.25.\n",
      "Grad(P[3][3]: -0.28.\n"
     ]
    }
   ],
   "source": [
    "# get gradient of our outcome\n",
    "def B_grad_a(A, P, i, j, As = As, Ps = Ps):\n",
    "    P_inv = np.linalg.inv(P)\n",
    "    Ps_inv = np.linalg.inv(Ps)\n",
    "    \n",
    "    B = np.matmul(P_inv, np.matmul(A, P))\n",
    "    Bs = np.matmul(Ps_inv, np.matmul(As, Ps))\n",
    "    \n",
    "    J = np.zeros((n, n))\n",
    "    J[i][j] = 1\n",
    "    \n",
    "    covariance_X = np.matmul(np.linalg.inv(np.identity(n ** 2) - np.kron(Bs, Bs)), Sigma.reshape(n ** 2)).reshape((n, n))\n",
    "\n",
    "    return -2 * np.trace(np.matmul(covariance_X, np.matmul((Bs - B).transpose(), np.matmul(P_inv, np.matmul(J, P)))))\n",
    "\n",
    "def B_grad_p(A, P, i, j, As = As, Ps = Ps):\n",
    "    P_inv = np.linalg.inv(P)\n",
    "    Ps_inv = np.linalg.inv(Ps)\n",
    "    \n",
    "    B = np.matmul(P_inv, np.matmul(A, P))\n",
    "    Bs = np.matmul(Ps_inv, np.matmul(As, Ps))\n",
    "    \n",
    "    J = np.zeros((n, n))\n",
    "    J[i][j] = 1\n",
    "    \n",
    "    covariance_X = np.matmul(np.linalg.inv(np.identity(n ** 2) - np.kron(Bs, Bs)), Sigma.reshape(n ** 2)).reshape((n, n))\n",
    "\n",
    "    B_grad = np.matmul(P_inv, np.matmul(A, J))\n",
    "    B_grad -= np.matmul(P_inv, np.matmul(J, np.matmul(P_inv, np.matmul(A, P))))\n",
    "    \n",
    "    return -2 * np.trace(np.matmul(covariance_X, np.matmul((Bs - B).transpose(), B_grad)))\n",
    "\n",
    "A = np.zeros((n, n))\n",
    "A[np.tril_indices(n)] = results.x[:6]\n",
    "p_coefs = results.x[6:]\n",
    "p_ds = np.array(sum(p * c for p, c in zip(p_coefs, permutation_list)))\n",
    "print(f\"A:\\n{np.round(A, 2)}\\n\\nP:\\n{np.round(p_ds, 2)}\\n\\n\")\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i + 1): \n",
    "        print(f\"Grad(A[{i+1}][{j+1}]: {np.round(B_grad_a(A, p_ds, i, j), 2)}.\")\n",
    "\n",
    "print()\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        print(f\"Grad(P[{i+1}][{j+1}]: {np.round(B_grad_p(A, p_ds, i, j), 2)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f307f8c6",
   "metadata": {},
   "source": [
    "## Gradient for cost function\n",
    "$$C(A, P) = \\text{Tr}\\left((B^* - B)\\Sigma_X(B^* - B)\\right)$$\n",
    "\n",
    "$$P = \\sum_{i=1}^{n!}\\lambda_i P_i$$\n",
    "\n",
    "$$\\frac{\\partial C(A, P)}{\\partial lambda_{i}} = \\frac{\\partial C(A, P)}{\\partial P"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bit874e3a48d9b148faaa09714964fd179b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
